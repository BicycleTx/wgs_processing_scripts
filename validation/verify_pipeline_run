#!/usr/bin/env bash

source message_functions || exit 1

print_usage(){
    echo "-----"
    echo " Descr: Verifies a new COLO829T Somatic pipeline run"
    echo " Usage: $(basename $0) -u <gcp_url> -o <out_dir> -t <truth_dir>"
    echo " Options:"
    echo "   -u  gcp_url    URL to run at GCP"
    echo "   -o  out_dir    Path to directory for verification"
    echo "   -t  truth_run  Path to directory of truth run"
    echo "   -f  force      Continue if output directory already exists"
    echo " Example:"
    echo "   $(basename $0) -u gs://path/to/rundir -o /path/to/p5_verification_v5.11 -t /path/to/run_v5.10"
    echo " Notes:"
    echo "   - Run with nohup since this includes downloading from GCP"
    echo "-----"
    exit 1
}

sanity_checks="TRUE"
while getopts ':fu:o:t:' flag; do
    case "${flag}" in
        f) sanity_checks="FALSE" ;;
        u) gcp_url=${OPTARG} ;;
        o) out_dir=${OPTARG} ;;
        t) truth_run=${OPTARG} ;;
        *) print_usage
        exit 1 ;;
    esac
done

if [[ -z "${gcp_url}" || -z "${out_dir}" || -z "${truth_run}" ]]; then
    print_usage
fi

main() {
    info "Starting with script $(basename $0)"
    
    ## some input sanity checks
    [[ -n "${out_dir}" && "${out_dir}" =~ ^\/ ]] || die "Incorrect out_dir format (${out_dir})?"
    [[ -n "${gcp_url}" && "${gcp_url}" =~ ^gs\:// ]] || die "Incorrect gcp_url format (${gcp_url})"
    if [[ "${sanity_checks}" == "TRUE" ]]; then
        [[ ! -d "${out_dir}" ]] || die "Dir exists (${out_dir})"
    fi

    info "Constructing variables"
    run_name=$(basename "${gcp_url}")
    runs_dir="${out_dir}/runs"
    jobs_dir="${out_dir}/jobs"
    logs_dir="${out_dir}/logs"
    run_dir="${runs_dir}/${run_name}"
    download_log="${logs_dir}/download.log"
    
    info "Creating directory structure"
    info "Run name: ${run_name}" 
    info "Out path: ${out_dir}"
    info "Runs directory: ${runs_dir}"
    info "Jobs directory: ${jobs_dir}"
    info "Logs directory: ${logs_dir}"
    
    mkdir -p "${out_dir}" "${runs_dir}" "${run_dir}" "${jobs_dir}" "${logs_dir}" || die "Unable to create dirs"
    cd "${out_dir}" || die "Unable to move to output directory"

    info "Gathering script and sql job files"
    jobs_source_path="/data/repos/scripts/validation"
    script_jobs=(
        "${jobs_source_path}/compare_v5_runs"
        "${jobs_source_path}/diff_v5_COLO829v003_runs"
        "/data/repos/scripts/hmftools/patientdb/load_run_into_reference_validation_sets_db"
        "/data/repos/scripts/functions/test/locate_files_test"
        "${jobs_source_path}/run_all_sql_verification_jobs"
    )
    sql_jobs=(
        "${jobs_source_path}/check_update_time.sql"
        "${jobs_source_path}/compare_metrics.sql"
        "${jobs_source_path}/compare_purity.sql"
        "${jobs_source_path}/counts_variants.sql"
        "${jobs_source_path}/diff_somatic_variants.sql"
        "${jobs_source_path}/diff_germline_variants.sql"
        "${jobs_source_path}/diff_sv.sql"
        "${jobs_source_path}/diff_sv_test.sql"
    )
    for job_file_path in "${script_jobs[@]}" "${sql_jobs[@]}"; do
        copy_file "${job_file_path}" "${jobs_dir}"
    done

    ## early fail in case pipeline.version does not exist
    file_to_check="pipeline.version"
    url_to_check="${gcp_url}/${file_to_check}"
    msg=$(gsutil ls "${url_to_check}" 2>&1)
    if [[ $? -eq 1 ]]; then
        warn "Cannot access file (${url_to_check})"
        warn "ErrCode=${?} ErrMsg=\"${msg}\""
        warn "Check run contents with: gsutil ls ${gcp_url}"
        exit 1
    else
        info "File ${file_to_check} found in bucket so assuming run is complete."
    fi

    download_run_from_gcp "${gcp_url}" "${run_dir}" "${download_log}"

    new_run="${run_dir}"

    metadata_file="${new_run}/metadata.json"
    info "Checking format of ${metadata_file}"
    check_metadata_json "${metadata_file}"

    info "Looking for anomalies in run.log files"
    find "${new_run}" -name "run.log" -exec grep -Pi "err|warn|exit|excep" {} + | grep -v germline_caller > "${logs_dir}/runlogs_check.txt"

    info "Executing locate_files test"
    "${jobs_dir}/locate_files_test" "${new_run}" > "${logs_dir}/locate_files_test.log" 2>&1

    info "Executing compare_v5_runs"
    out_log="${logs_dir}/compare_v5_runs.log"
    err_log="${logs_dir}/compare_v5_runs.err"
    "${jobs_dir}/compare_v5_runs" "${truth_run}" "${new_run}" > "${out_log}" 2>"${err_log}"

    info "Executing diff_v5_COLO829v003_runs"
    "${jobs_dir}/diff_v5_COLO829v003_runs" "${truth_run}" "${new_run}" > "${logs_dir}/diff_v5_COLO829v003_runs.log" 2>&1

    db_load_script="load_run_into_pipeline_v5_validation_db"
    sql_query_script="run_all_sql_verification_jobs"
    info "TODO manual steps:"
    info " 1) Inspect all log files in ${logs_dir}"
    info " 2) Execute sql queries (nohup ${sql_query_script} ${jobs_dir} ${logs_dir} before_load > ${logs_dir}/run_all_sql_verification_jobs_before_load.log &)"
    info " 3) Load into DB (nohup ${db_load_script} ${new_run} > ${logs_dir}/${db_load_script}.log &)"
    info " 4) Execute sql queries again after load (nohup ${sql_query_script}  ${jobs_dir} ${logs_dir} after_load > ${logs_dir}/run_all_sql_verification_jobs_after_load.log &)"
    info " 5) Inspect all SQL log files in logs dir (ls ${logs_dir})"
    info "Finished with $(basename $0)"
}

download_run_from_gcp() {
    local gcp_url=$1 && shift
    local target_dir=$1 && shift
    local log_file=$1 && shift
    local check_log="${log_file}.check"
    
    touch "${log_file}"
    touch "${check_log}"
    
    info "Starting download from GCP (you can track progress in log ${log_file})"
    gsutil -m -o GSUtil:parallel_process_count=7 -o GSUtil:parallel_thread_count=1 rsync \
        -r -x ".*\.bam$|.*\.cram$" "${gcp_url}/" "${run_dir}/" \
        > "${log_file}" 2>&1 || die "Something went wrong with download"

    info "Starting re-download from GCP (to check sync completeness)"
    gsutil -m -o GSUtil:parallel_process_count=7 -o GSUtil:parallel_thread_count=1 rsync \
        -r -x ".*\.bam$|.*\.cram$" "${gcp_url}/" "${run_dir}/" \
        > "${log_file}.check" 2>&1 || die "Something went wrong with re-download"

    line_count=$(grep -cvP "Building sync|Starting sync" "${check_log}")
    [[ "${line_count}" -eq 0 ]] || die "Download check log seems to contain downloaded files (pls check ${check_log})"
}

copy_file() {
    local file_path=$1 && shift
    local target_dir=$1 && shift

    if [[ ! -f "${file_path}" ]]; then
        die "File not found (${file_path})"
    else
        info "Copying file ($file_path)"
        cp "${file_path}" "${jobs_dir}"
        [[ $? -eq 0 ]] || die "Unable to copy file (${file_path}) to dir (${target_dir})"
    fi
}

check_metadata_json() {
    local metadata_json=$1 && shift
    fields_to_check=(
        '.set'
        '.reference.sampleName'
        '.reference.barcode'
        '.tumor.sampleName'
        '.tumor.barcode'
    )
    for field in ${fields_to_check[*]}; do
        if [[ $(jq "select(${field} == null)" "${metadata_json}") ]]; then
            warn "Field ${field} absent metadata (${metadata_json})"
        else
            info "OK field found in metadata (${field})"
        fi
    done
}

main
