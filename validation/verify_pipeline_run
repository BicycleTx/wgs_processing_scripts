#!/usr/bin/env bash

print_usage(){
    echo "-----"
    echo " Descr: Verifies a new COLO829T Somatic pipeline run"
    echo " Usage: $(basename $0) -u <gcp_url> -o <out_dir> -t <truth_dir>"
    echo " Options:"
    echo "   -u  gcp_url    URL to run at GCP"
    echo "   -o  out_dir    Path to directory for verification"
    echo "   -t  truth_run  Path to directory of truth run"
    echo " Example:"
    echo "   $(basename $0) -u gs://path/to/run/ -o /path/to/p5_verification_v5.11 -t /path/to/run_v5.10"
    echo " Notes:"
    echo "   - Run with nohup since this includes downloading from GCP"
    echo "-----"
    exit 1
}

while getopts ':u:o:t:' flag; do
    case "${flag}" in
        u) gcp_url=${OPTARG} ;;
        o) out_dir=${OPTARG} ;;
        t) truth_run=${OPTARG} ;;
        *) print_usage
        exit 1 ;;
    esac
done

if [[ -z "${gcp_url}" || -z "${out_dir}" || -z "${truth_run}" ]]; then
    print_usage
fi

main() {
    info "Starting with script $(basename $0)"
    
    ## some input sanity checks
    [[ ! -z "${out_dir}" && "${out_dir}" =~ ^\/ ]] || die "Incorrect out_dir (${out_dir})?"
    [[ ! -z "${gcp_url}" && "${gcp_url}" =~ ^gs\:// ]] || die "Incorrect gcp_url (${gcp_url})"
    [[ ! -d "${out_dir}" ]] || die "Dir exists (${out_dir})"

    info "Constructing variables"
    run_name=$(basename "${gcp_url}")
    runs_dir="${out_dir}/runs"
    jobs_dir="${out_dir}/jobs"
    logs_dir="${out_dir}/logs"
    run_dir="${runs_dir}/${run_name}"
    download_log="${logs_dir}/download.log"
    
    info "Creating directory structure"
    info "Run name: ${run_name}" 
    info "Out path: ${out_dir}"
    info "Runs directory: ${runs_dir}"
    info "Jobs directory: ${jobs_dir}"
    info "Logs directory: ${logs_dir}"
    
    mkdir "${out_dir}" "${runs_dir}" "${run_dir}" "${jobs_dir}" "${logs_dir}" || die "Unable to create dirs"
    cd "${out_dir}" || die "Unable to move to output directory"

    info "Gathering script and sql job files"
    jobs_source_path="/data/common/repos/scripts/validation"
    script_jobs=(
        "${jobs_source_path}/compare_v5_runs"
        "${jobs_source_path}/diff_v5_COLO829v003_runs"
        "/data/common/repos/scripts/hmftools/patientreporter/create_patient_report_for_run"
        "/data/common/repos/scripts/hmftools/patientdb/load_run_into_reference_validation_sets_db"
        "/data/common/repos/scripts/functions/test/locate_files_test"
        "${jobs_source_path}/run_all_sql_verification_jobs"
    )
    sql_jobs=(
        "${jobs_source_path}/check_update_time.sql"
        "${jobs_source_path}/compare_metrics.sql"
        "${jobs_source_path}/compare_purity.sql"
        "${jobs_source_path}/counts_variants.sql"
        "${jobs_source_path}/diff_somatic_variants.sql"
        "${jobs_source_path}/diff_germline_variants.sql"
        "${jobs_source_path}/diff_sv.sql"
        "${jobs_source_path}/diff_sv_test.sql"
    )
    for job_file_path in "${script_jobs[@]}" "${sql_jobs[@]}"; do
        copy_file "${job_file_path}" "${jobs_dir}"
    done

    ## early fail in case pipeline.version does not exist
    file_to_check="pipeline.version"
    url_to_check="${gcp_url}/${file_to_check}"
    msg=$(gsutil ls "${url_to_check}" 2>&1)
    if [[ $? -eq 1 ]]; then
        echo "[ERROR] Cannot access file (${url_to_check})"
        echo "[ERROR] ErrCode=${?} ErrMsg=\"${msg}\""
        echo "[ERROR] Check run contents with: gsutil ls ${gcp_url}"
        exit 1
    else
        info "File ${file_to_check} found in bucket so assuming run is complete."
    fi

    download_run_from_gcp "${gcp_url}" "${run_dir}" "${download_log}"

    new_run="${run_dir}"

    metadata_file="${new_run}/metadata.json"
    info "Checking format of ${metadata_file}"
    check_metadata_json "${metadata_file}"

    info "Looking for anomalies in run.log files"
    find "${new_run}" -name "run.log" -exec grep -Pi "err|warn|exit|excep" {} + | grep -v germline_caller > "${logs_dir}/runlogs_check.txt"

    info "Executing locate_files test"
    "${jobs_dir}/locate_files_test" "${new_run}" > "${logs_dir}/locate_files_test.log" 2>&1

    info "Executing compare_v5_runs"
    "${jobs_dir}/compare_v5_runs" "${truth_run}" "${new_run}" "${logs_dir}" > "${logs_dir}/compare_v5_runs.log" 2>&1

    info "Executing diff_v5_COLO829v003_runs"
    "${jobs_dir}/diff_v5_COLO829v003_runs" "${truth_run}" "${new_run}" > "${logs_dir}/diff_v5_COLO829v003_runs.log" 2>&1

    db_load_script="load_run_into_pipeline_v5_validation_db"
    info "TODO manual steps:"
    info " 1) Inspect all log files in ${logs_dir}"
    info " 2) Execute \"before\" queries (see run_all_sql_verification_jobs in ${jobs_dir})"
    info " 3) Load into DB (nohup ${db_load_script} ${new_run} > ${logs_dir}/${db_load_script}.log &"
    info " 4) Execute \"after\" queries (see run_all_sql_verification_jobs in ${jobs_dir})"
    info " 5) Inspect all SQL log files in ${logs_dir}"
    info "Finished with $(basename $0)"
}

download_run_from_gcp() {
    local gcp_url=$1 && shift
    local target_dir=$1 && shift
    local log_file=$1 && shift
    local check_log="${log_file}.check"
    
    touch "${log_file}"
    touch "${check_log}"
    
    info "Starting download from GCP (you can track progress in log ${log_file})"
    gsutil -m rsync -r "${gcp_url}/" "${run_dir}/" > "${log_file}" 2>&1
    [[ $? -eq 0 ]] || die "Something went wrong with download"

    info "Starting re-download from GCP (to check sync completeness)"
    gsutil -m rsync -r "${gcp_url}/" "${run_dir}/" > "${log_file}.check" 2>&1
    [[ $? -eq 0 ]] || die "Something went wrong with re-download"

    line_count=$(cat "${check_log}" | grep -v 'Building sync' | grep -v 'Starting sync' | wc -l)
    [[ "${line_count}" -eq 0 ]] || die "Download check log seems to contain downloaded files (pls check ${check_log})"
}

copy_file() {
    local file_path=$1 && shift
    local target_dir=$1 && shift

    if [[ ! -f "${file_path}" ]]; then
        die "File not found (${file_path})"
    else
        info "Copying file ($file_path)"
        cp "${file_path}" "${jobs_dir}"
        [[ $? -eq 0 ]] || die "Unable to copy file (${file_path}) to dir (${target_dir})"
    fi
}

check_metadata_json() {
    local metadata_json=$1 && shift
    fields_to_check=(
        '.set'
        '.reference.sampleName'
        '.reference.barcode'
        '.tumor.sampleName'
        '.tumor.barcode'
    )
    for field in ${fields_to_check[*]}; do
        if [[ $(jq "select(${field} == null)" "${metadata_json}") ]]; then
            warn "Field ${field} absent metadata (${metadata_json})"
        else
            info "OK field found in metadata (${field})"
        fi
    done
}

print_sql_code() {
    local output_file=$1 && shift
    local log_file=$1 && shift
    echo "find ${jobs_dir} -type f -name \"*.sql\" | while read sql_file ; do"
    echo "  sql_file_name=\"$(basename $sql_file)\" "
    echo "  log_file=\"${logs_dir}/before_load_\${sql_file_name}.log\" "
    echo "  echo \"[INFO] Executing \$sql_file_name (log: \$log_file)\" "
    echo "  execute_sql_on_prod \"\$sql_file\" > \"\${log_file}\" "
    echo "done"
}

die() { 
    echo "[ERROR] $(date +"%y%m%d %T")" "$@" >&2
    exit 1 
}
warn() { 
    echo "[WARN] $(date +"%y%m%d %T")" "$@" >&2
}
info() { 
    echo "[INFO] $(date +"%y%m%d %T")" "$@"
}

main
