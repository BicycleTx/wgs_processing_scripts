#!/usr/bin/env bash

set -e

flowcells_dir="/data1/illumina_data"
bucket="bcl-input-prod-1"
gcp_cred="/data/dbs/gcp_credentials/bcl-input-prod"

function exit_handler() {
    gcloud logging write on_premises "ERROR while uploading flowcells" --severity=ERROR --project=hmf-pipeline-prod-e45b00f2
}

function rsync_bcls() {
    gsutil -m -o GSUtil:parallel_process_count=7 -o GSUtil:parallel_thread_count=1 -o GSUtil:parallel_composite_upload_threshold=350M \
        rsync -r -x ".*Fastq.*|.*Logs.*|.*Images.*|.*PeriodicSaveRates.*|.*fastq\.gz|.*BaseCalls/[^L].*|.*\.tmp\..*|RTAComplete.txt" "$1" "$2"
}

trap exit_handler EXIT

while true; do
    find "${flowcells_dir}" -mindepth 1 -maxdepth 1 -type d -not -name "TestRuns" -not -name "MyRun" | while read -r flowcell_path; do
        echo "Starting BCL upload of ${flowcell_path}"
        gs_path="gs://${bucket}/$(basename $flowcell_path)"
        gcloud auth activate-service-account --key-file "${gcp_cred}"
        rsync_bcls $flowcell_path $gs_path
    
        rtacomplete_path="${flowcell_path}/RTAComplete.txt"
        if [[ -f "${rtacomplete_path}" ]]; then
          date --date="@$(stat -c '%Y' "${rtacomplete_path}")" "+%Y-%m-%d %H:%M:%S %z" > ${flowcell_path}/RTAComplete.timestamp
          rsync_bcls $flowcell_path $gs_path
          gsutil cp ${rtacomplete_path} $gs_path
        fi
        echo "${flowcell_path} upload succeeded"
    done
done

