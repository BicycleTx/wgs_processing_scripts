#!/usr/bin/env bash

set_name=$1
cmd_date=$(date)

if [[ -z "$set_name" ]]; then
    echo "[ERROR] No set provided. Exiting" && exit 1
fi

api_cred_dir="/data/common/dbs/api_credentials"
gcp_cred_dir="/data/common/dbs/gcp_credentials"

api_url="https://api.hartwigmedicalfoundation.nl/hmf/v1"
api_crt_file="${api_cred_dir}/api.crt"
api_key_file="${api_cred_dir}/api.key"

gcp_url_sign_script="generate_signed_gcp_url.py"
gcp_key_file="${gcp_cred_dir}/hmf-download"
gcp_project="hmf-database"
gcp_account="hmf-download"

echo "[INFO] Start of $0 ($cmd_date)"
msg=$(gcloud config set account "${gcp_account}@${gcp_project}.iam.gserviceaccount.com" 2>&1)
echo "[INFO] $msg"

function main() {
    ## check that only one run exists for the set
    runs_json=$(query_api -type runs -filter "name=$set_name" -exact -json | jq '.')
    runs_count=$(echo "$runs_json" | jq '. | length')
    if [[ "$runs_count" -ne 1 ]]; then
        echo "[ERROR] Only sets supported with exactly one run (found $runs_count). Exiting" && exit 1
    fi
    run_json=$(echo "$runs_json" | jq -r '.[-1]')

    ## setup all variables
    cluster=$(echo "$run_json" | jq -r '.cluster')
    bucket=$(echo "$run_json" | jq -r '.bucket')
    entity=$(echo "$run_json" | jq -r '.entity')
    status=$(echo "$run_json" | jq -r '.status')
    name=$(echo "$run_json" | jq -r '.name')
    pip=$(echo "$run_json" | jq -r '.pipeline')
    ini=$(echo "$run_json" | jq -r '.ini')
    ref=$(echo "$run_json" | jq -r '.ref_sample')
    tum=$(echo "$run_json" | jq -r '.tumor_sample')
    oid=$(echo "$run_json" | jq -r '.id') # object id

    files_api_url="${api_url}/files?run_id=${oid}"
    out_jsn_all="${name}_runfiles.json"
    out_md5_all="${name}_runfiles.md5"
    out_aria="${name}.aria.txt"
    out_md5="${name}.md5"
    out_url="${name}.url"

    echo "[INFO] RunName: $name"
    echo "[INFO] RunStat: $status"
    echo "[INFO] IniName: $ini"
    echo "[INFO] TumName: $tum"
    echo "[INFO] RefName: $ref"
    echo "[INFO] PipeVsn: $pip"
    echo "[INFO] Cluster: $cluster"
    echo "[INFO] Bucket:  $bucket"
    echo "[INFO] Entity:  $entity"
    
    ## sanity check on data location in API
    ## TODO once all at gcp then remove the ini check
    if [[ $cluster != "gcp" && $ini != "FastQ.ini" ]]; then
       echo "[EXIT] Error: unexpected cluster ($cluster)." && exit 1
    fi

    ## cleanup existing files
    for output_file in "$out_jsn_all" "$out_md5_all" "$out_aria" "$out_md5" "$out_url"; do
        if [[ -f $output_file ]]; then
            echo "[INFO] Deleting existing file ($output_file)" && rm $output_file;
        fi
    done

    ## get the file objects for one run by id
    files_json=$(/usr/bin/curl --silent --cert-type pem \
        --cert ${api_crt_file} --key ${api_key_file} -X GET \
        -H "Accept: application/json" -H "Content-Type: application/json" \
        "$files_api_url")

    ## create run type agnostic info files
    create_json_file "$files_json" "$out_jsn_all"
    create_md5sums_file "$files_json" "$out_md5_all"

    ## create the run type specific subset files
    if [[ $ini == "FastQ.ini" ]]; then
        create_run_specific_files "$files_json" "$out_md5" "$out_aria" "$out_url" "$name" "$bucket" "$ref" "$tum" "Fastq"
    elif [[ $ini == "Somatic.ini" ]]; then 
        create_run_specific_files "$files_json" "$out_md5" "$out_aria" "$out_url" "$name" "$bucket" "$ref" "$tum" "Somatic"
    elif [[ $ini == "SingleSample.ini" ]]; then
        create_run_specific_files "$files_json" "$out_md5" "$out_aria" "$out_url" "$name" "$bucket" "$ref" "$tum" "SingleSample"
    else
        echo "[EXIT] Unknown ini ($ini)" && exit 1
    fi

    ## sanity checks on final files
    for output_file in "$out_jsn_all" "$out_md5_all" "$out_aria" "$out_md5" "$out_url"; do
        line_count=$(cat "$output_file" | wc -l)
        echo "[INFO] Output file $output_file contains $line_count lines"
    done
}

create_run_specific_files () {
    local json=$1 && shift
    local out_md5=$1 && shift
    local out_aria=$1 && shift
    local out_url=$1 && shift
    local name=$1 && shift
    local bucket=$1 && shift
    local ref=$1 && shift
    local tum=$1 && shift
    local run_type=$1 && shift

    ref_bam="${ref}/aligner/${ref}.bam"
    ref_bam_bai="${ref}/aligner/${ref}.bam.bai"
    tumor_bam="${tum}/aligner/${tum}.bam"
    tumor_bam_bai="${tum}/aligner/${tum}.bam.bai"

    mapfile -t all_files < <( echo $json | jq -r '.[].filename' )

    local single_files=(
        "${ref_bam}"
        "${ref_bam_bai}"
        "${ref}/germline_caller/${ref}.germline.vcf.gz"
        "${ref}/germline_caller/${ref}.germline.vcf.gz.tbi"
    )

    local somatic_files=(
        "purple/purple.version"
        "purple/${tum}.driver.catalog.tsv"
        "purple/${tum}.purple.cnv.somatic.tsv"
        "purple/${tum}.purple.cnv.gene.tsv"
        "purple/${tum}.purple.purity.tsv"
        "purple/${tum}.purple.purity.range.tsv"
        "purple/${tum}.purple.qc"
        "purple/${tum}.purple.sv.vcf.gz"
        "purple/${tum}.purple.sv.vcf.gz.tbi"
        "purple/${tum}.purple.somatic.vcf.gz"
        "purple/${tum}.purple.somatic.vcf.gz.tbi"
        "purple/${tum}.purple.cnv.germline.tsv"
        "purple/plot/${tum}.circos.png"
        "${ref_bam}"
        "${ref_bam_bai}"
        "${tumor_bam}"
        "${tumor_bam_bai}"
        "${ref}/germline_caller/${ref}.germline.vcf.gz"
        "${ref}/germline_caller/${ref}.germline.vcf.gz.tbi"
    )

    ## select file collection
    if [[ $run_type == "Somatic" ]]; then
        file_selection="${somatic_files[@]}"
    elif [[ $run_type == "SingleSample" ]]; then
        file_selection="${single_files[@]}"
    elif [[ $run_type == "Fastq" ]]; then
        file_selection="${all_files[@]}"
    else
        echo "[EXIT] Unknown run type ($run_type)" && exit 1
    fi

    ## output aria2 config file
    echo "[INFO] Creating $out_aria (and selection tmp files)"
    for file_path in ${file_selection[@]}; do
        file_name=$(basename "${file_path}")
        file_in_bucket="${bucket}/${name}/${file_path}"
        ## Fastq files are at main level in the bucket
        if [[ $run_type == "Fastq" ]]; then
            file_in_bucket="${bucket}/${file_path}"
        fi
        internal_url="gs://${file_in_bucket}"
        md5_string=$(echo "$json" | jq -r '.[] | .hash + "\t" + .directory + "/" + .filename' | grep -P "${file_path}$")
        md5sum=$(echo "$md5_string" | cut -f1)
        echo "${md5_string}" >> $out_md5

        ## sanity check on existance of file in bucket
        gsutil -u "${gcp_project}" -q stat "${internal_url}"
        if [[ $? -eq 1 ]]; then
            msg=$(gsutil -u "${gcp_project}" ls "${internal_url}" 2>&1)
            echo "[EXIT] Cannot access file (${internal_url})"
            echo "[EXIT] ErrCode=${?} ErrMsg=\"${msg}\""
            exit 1
        fi

        ## get actual pre-signed URL
        external_url=$( "${gcp_url_sign_script}" "${gcp_key_file}" "${file_in_bucket}" 604800)

        echo "${external_url}" >> $out_aria
        echo "  dir=${name}" >> $out_aria
        echo "  checksum=md5=${md5sum}" >> $out_aria
        echo "" >> $out_aria
        echo -e "${file_name}\t${external_url}" >> $out_url
    done
}

create_json_file () {
    local json_text=$1 && shift
    local out_file=$1 && shift
    echo "[INFO] Creating $out_file"
    echo "$json_text" | jq '.' > $out_file
}

create_md5sums_file () {
    local json_text=$1 && shift
    local out_file=$1 && shift
    echo "[INFO] Creating $out_file"
    echo "$json_text" | jq -r '.[] | select(.directory == "") | .hash + "  " + .filename' > $out_file
    echo "$json_text" | jq -r '.[] | select(.directory != "") | .hash + "  " + .directory + "/" + .filename' >> $out_file
}

main
