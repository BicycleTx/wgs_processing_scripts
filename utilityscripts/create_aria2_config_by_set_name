#!/usr/bin/env bash

source message_functions || exit 1

set_name=$1

if [[ -z "${set_name}" ]]; then
    echo "[ERROR] No set provided. Exiting" && exit 1
fi

api_cred_dir="/data/common/dbs/api_credentials"
gcp_cred_dir="/data/common/dbs/gcp_credentials"

api_url="https://api.hartwigmedicalfoundation.nl/hmf/v1"
api_crt_file="${api_cred_dir}/api.crt"
api_key_file="${api_cred_dir}/api.key"

gcp_url_sign_script="generate_signed_gcp_url.py"
gcp_key_file="${gcp_cred_dir}/hmf-ops"
gcp_project="hmf-database"
gcp_account="hmf-ops"

info "Start of $(basename $0)"
msg=$(gcloud config set account "${gcp_account}@${gcp_project}.iam.gserviceaccount.com" 2>&1)
info "${msg}"

function main() {
    ## check that only one run exists for the set
    runs_json=$(query_api.pl -type runs -filter "name=${set_name}" -exact -json | jq '.')
    runs_count=$(echo "${runs_json}" | jq '. | length')
    if [[ "${runs_count}" -ne 1 ]]; then
        die "Only sets supported with exactly one run (found ${runs_count}). Exiting"
    fi
    run_json=$(echo "${runs_json}" | jq -r '.[-1]')

    ## setup all variables
    cluster=$(echo "${run_json}" | jq -r '.cluster')
    bucket=$(echo "${run_json}" | jq -r '.bucket')
    entity=$(echo "${run_json}" | jq -r '.entity')
    status=$(echo "${run_json}" | jq -r '.status')
    name=$(echo "${run_json}" | jq -r '.name')
    pip=$(echo "${run_json}" | jq -r '.pipeline')
    ini=$(echo "${run_json}" | jq -r '.ini')
    ref=$(echo "${run_json}" | jq -r '.ref_sample')
    tum=$(echo "${run_json}" | jq -r '.tumor_sample')
    oid=$(echo "${run_json}" | jq -r '.id') # object id

    files_api_url="${api_url}/files?run_id=${oid}"
    out_jsn_all="${name}_runfiles.json"
    out_md5_all="${name}_runfiles.md5"
    out_aria="${name}.aria.txt"
    out_md5="${name}.md5"
    out_url_int="${name}_internal_urls.txt"
    out_url_ext="${name}_external_urls.txt"

    info "RunName: ${name}"
    info "RunStat: ${status}"
    info "IniName: ${ini}"
    info "TumName: ${tum}"
    info "RefName: ${ref}"
    info "PipeVsn: ${pip}"
    info "Cluster: ${cluster}"
    info "Bucket:  ${bucket}"
    info "Entity:  ${entity}"
    
    ## create re-usable list of all output files
    output_files=("${out_jsn_all}" "${out_md5_all}" "${out_aria}" "${out_md5}" "${out_url_int}" "${out_url_ext}")

    ## cleanup existing files
    for output_file in "${output_files[@]}"; do
        if [[ -f "${output_file}" ]]; then
            info "Deleting existing file (${output_file})" && rm "${output_file}";
        fi
    done

    ## get the file objects for one run by id
    files_json=$(curl --silent --cert-type pem \
        --cert ${api_crt_file} --key ${api_key_file} -X GET \
        -H "Accept: application/json" -H "Content-Type: application/json" \
        "${files_api_url}")

    ## create run type agnostic info files
    create_json_file "${files_json}" "${out_jsn_all}"
    create_md5sums_file "${files_json}" "${out_md5_all}"

    ## create the run type specific subset files
    if [[ "${ini}" == "FastQ.ini" || "${ini}" == "Rna.ini" ]]; then
        create_run_specific_files "${files_json}" \
        "${out_md5}" "${out_aria}" "${out_url_int}" "${out_url_ext}" "${name}" "${bucket}" "${ref}" "${tum}" "${pip}" "Fastq"
    elif [[ "${ini}" == "Somatic.ini" ]]; then
        create_run_specific_files "${files_json}" \
        "${out_md5}" "${out_aria}" "${out_url_int}" "${out_url_ext}" "${name}" "${bucket}" "${ref}" "${tum}" "${pip}" "Somatic"
    elif [[ "${ini}" == "SingleSample.ini" ]]; then
        create_run_specific_files "${files_json}" \
        "${out_md5}" "${out_aria}" "${out_url_int}" "${out_url_ext}" "${name}" "${bucket}" "${ref}" "${tum}" "${pip}" "SingleSample"
    elif [[ "${ini}" == "ShallowSeq.ini" ]]; then
        create_run_specific_files "${files_json}" \
        "${out_md5}" "${out_aria}" "${out_url_int}" "${out_url_ext}" "${name}" "${bucket}" "${ref}" "${tum}" "${pip}" "ShallowSeq"
    else
        die "Unknown ini (${ini})"
    fi

    ## output check
    info "Output files:"
    for output_file in "${output_files[@]}"; do
        if [[ ! -f "${output_file}" ]]; then
            die "Output file ${output_file} not found!"
        else
            line_count=$(wc -l "${output_file}" | cut -d" " -f1)
            info "  ${output_file} (${line_count} lines)"
        fi
    done

    info "Finished with $(basename $0)"
}

create_run_specific_files () {
    local json=$1 && shift
    local out_md5=$1 && shift
    local out_aria=$1 && shift
    local out_url_int=$1 && shift
    local out_url_ext=$1 && shift
    local name=$1 && shift
    local bucket=$1 && shift
    local ref=$1 && shift
    local tum=$1 && shift
    local pip=$1 && shift
    local run_type=$1 && shift
    local minor=""

    if [[ "${run_type}" == "Fastq" ]]; then
        pip="Fastq"
    elif [[ "${pip}" =~ ^v5\.[0-9]+\.[0-9]+$ ]]; then
        minor=$(echo "${pip}" | cut -d"." -f2)
    else
        die "Pipeline version string has unknown format (${pip})"
        exit 1
    fi
 
    ## from pipeline v5.10 onwards CRAM replaced BAM
    if [[ "${pip}" == "Fastq" ]]; then
        ## for fastq type runs no pipeline output is available
        ref_bam="undef"
        ref_bam_bai="undef"
        tumor_bam="undef"
        tumor_bam_bai="undef"
    elif [[ "${minor}" -lt 10 ]]; then
        ref_bam="${ref}/aligner/${ref}.bam"
        ref_bam_bai="${ref}/aligner/${ref}.bam.bai"
        tumor_bam="${tum}/aligner/${tum}.bam"
        tumor_bam_bai="${tum}/aligner/${tum}.bam.bai"
    else
        ref_bam="${ref}/cram/${ref}.cram"
        ref_bam_bai="${ref}/cram/${ref}.cram.crai"
        tumor_bam="${tum}/cram/${tum}.cram"
        tumor_bam_bai="${tum}/cram/${tum}.cram.crai"
    fi

    mapfile -t all_file_paths < <( echo "${json}" | jq -r '.[].filepath' )

    local single_files=(
        "${ref_bam}"
        "${ref_bam_bai}"
        "${ref}/germline_caller/${ref}.germline.vcf.gz"
        "${ref}/germline_caller/${ref}.germline.vcf.gz.tbi"
    )

    local shallow_files=(
        "${ref_bam}"
        "${ref_bam_bai}"
        "${tumor_bam}"
        "${tumor_bam_bai}"
    )

    local somatic_files=(
        "purple/purple.version"
        "purple/${tum}.driver.catalog.tsv"
        "purple/${tum}.purple.cnv.somatic.tsv"
        "purple/${tum}.purple.cnv.gene.tsv"
        "purple/${tum}.purple.purity.tsv"
        "purple/${tum}.purple.purity.range.tsv"
        "purple/${tum}.purple.qc"
        "purple/${tum}.purple.sv.vcf.gz"
        "purple/${tum}.purple.sv.vcf.gz.tbi"
        "purple/${tum}.purple.somatic.vcf.gz"
        "purple/${tum}.purple.somatic.vcf.gz.tbi"
        "purple/${tum}.purple.cnv.germline.tsv"
        "purple/plot/${tum}.circos.png"
        "${ref_bam}"
        "${ref_bam_bai}"
        "${tumor_bam}"
        "${tumor_bam_bai}"
        "${ref}/germline_caller/${ref}.germline.vcf.gz"
        "${ref}/germline_caller/${ref}.germline.vcf.gz.tbi"
    )

    ## select file collection
    if [[ ${run_type} == "Somatic" ]]; then
        file_selection=("${somatic_files[@]}")
    elif [[ ${run_type} == "ShallowSeq" ]]; then
        file_selection=("${shallow_files[@]}")
    elif [[ ${run_type} == "SingleSample" ]]; then
        file_selection=("${single_files[@]}")
    elif [[ ${run_type} == "Fastq" ]]; then
        file_selection=("${all_file_paths[@]}")
    else
        die "Unknown run type (${run_type})"
    fi

    ## output aria2 config file
    info "Creating ${out_aria} (and selection tmp files)"
    for file_path in "${file_selection[@]}"; do
        file_name=$(basename "${file_path}")
        file_in_bucket="${bucket}/${name}/${file_path}"
        internal_url="gs://${file_in_bucket}"

        ## adjust for Fastq files (those already are complete internal gs path)
        if [[ ${run_type} == "Fastq" ]]; then
            file_in_bucket=${file_path/gs\:\/\//}
            internal_url="${file_path}"
        fi

        ## get file specific md5 hash
        md5sum=$(echo "${json}" | jq -r --arg url "${internal_url}" '.[] | select(.filepath == $url) | .hash')
        [[ -n "${md5sum}" ]] || die "Missing md5 hash for file at url (${internal_url})"
        printf '%s\t%s\n' "${md5sum}" "${file_name}" >> "${out_md5}"

        ## sanity check on existance of file in bucket
        gsutil -u "${gcp_project}" -q stat "${internal_url}"
        if [[ $? -eq 1 ]]; then
            msg=$(gsutil -u "${gcp_project}" ls "${internal_url}" 2>&1)
            warn "Cannot access file so skipping (${internal_url})"
            warn "ErrCode=${?} ErrMsg=\"${msg}\""
            continue
        fi

        ## get actual pre-signed URL
        external_url=$( "${gcp_url_sign_script}" "${gcp_key_file}" "${file_in_bucket}" 604800)

        echo "${external_url}" >> "${out_aria}"
        echo "  dir=${name}" >> "${out_aria}"
        echo "  checksum=md5=${md5sum}" >> "${out_aria}"
        echo "" >> "${out_aria}"

        ## write urls to separate log files
        echo "${internal_url}" >> "${out_url_int}"
        echo "${external_url}" >> "${out_url_ext}"
    done
}

create_json_file () {
    local json_text=$1 && shift
    local out_file=$1 && shift
    info "Creating ${out_file}"
    echo "${json_text}" | jq '.' > "${out_file}"
}

create_md5sums_file () {
    local json_text=$1 && shift
    local out_file=$1 && shift
    info "Creating ${out_file}"
    echo "${json_text}" | jq -r '.[] | select(.directory == "") | .hash + "  " + .filename' > "${out_file}"
    echo "${json_text}" | jq -r '.[] | select(.directory != "") | .hash + "  " + .directory + "/" + .filename' >> "${out_file}"
}

main

